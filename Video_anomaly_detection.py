# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11GCSBJN_S5Qxs1L_3cu4MvGSedGdn0gh
"""

# ✅ Install YOLOv8 and dependencies
!pip install ultralytics --quiet
!pip install opencv-python-headless --quiet

# First uninstall existing packages
!pip uninstall torch torchvision torchaudio -y

# Then install the specific versions that work together
!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118

import torch
import torchvision
import torchaudio

# Check torch version
print(torch.__version__)
print(torchvision.__version__)
print(torchaudio.__version__)

# Verify CUDA is available
print(torch.cuda.is_available())

!pip install torch torchvision opencv-python

pip install --upgrade opencv-python

# Initialize YOLO model
from ultralytics import YOLO
model = YOLO('yolov8n.pt')  # Add this line

import torch
import cv2
import numpy as np
from torchvision import models, transforms
from torch.nn import functional as F
from torch import nn
import os
from google.colab.patches import cv2_imshow
from torch.utils.data import Dataset, DataLoader
import time
from sklearn.model_selection import train_test_split
from PIL import Image



import zipfile
import os
import shutil

# 🔓 Unzip your dataset (replace with your actual filename)
zip_path = '/content/drive/MyDrive/archive (2).zip'  # CHANGE if needed
extract_to = '/content/UCF-Crime-Dataset'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("✅ Dataset unzipped.")

source_train = '/content/UCF-Crime-Dataset/Train'
source_test = '/content/UCF-Crime-Dataset/Test'

target_train = '/content/UCF-Crime-Selected/Train'
target_test = '/content/UCF-Crime-Selected/Test'

folders_to_copy = ['Fighting', 'NormalVideos', 'RoadAccidents', 'Shoplifting']

# Create target directories
os.makedirs(target_train, exist_ok=True)
os.makedirs(target_test, exist_ok=True)

def copy_selected(source_folder, target_folder, folders):
    for folder in folders:
        src = os.path.join(source_folder, folder)
        tgt = os.path.join(target_folder, folder)
        if os.path.exists(src):
            shutil.copytree(src, tgt, dirs_exist_ok=True)
            print(f"✅ Copied: {folder}")
        else:
            print(f"⚠️ Not found: {folder}")

copy_selected(source_train, target_train, folders_to_copy)
copy_selected(source_test, target_test, folders_to_copy)

print("✅ Selected classes copied to /content/UCF-Crime-Selected/")

import pandas as pd

def detect_objects_and_save(frame_folder, output_csv):
    data = []

    for split in ['Train', 'Test']:
        split_path = os.path.join(frame_folder, split)

        for class_name in os.listdir(split_path):
            class_path = os.path.join(split_path, class_name)

            for video_name in os.listdir(class_path):
                video_path = os.path.join(class_path, video_name)

                for frame_name in os.listdir(video_path):
                    frame_path = os.path.join(video_path, frame_name)
                    results = model.predict(frame_path, conf=0.4, verbose=False)

                    boxes = results[0].boxes.xyxy.cpu().numpy()
                    classes = results[0].boxes.cls.cpu().numpy()

                    for box, cls in zip(boxes, classes):
                        data.append({
                            'split': split,
                            'class_name': class_name,
                            'video_name': video_name,
                            'frame_path': frame_path,
                            'xmin': box[0],
                            'ymin': box[1],
                            'xmax': box[2],
                            'ymax': box[3],
                            'class_id': int(cls)
                        })

    # Save detections into CSV
    df = pd.DataFrame(data)
    df.to_csv(output_csv, index=False)
    print(f"✅ Object detections saved to {output_csv}")

# Run it
detect_objects_and_save('/content/UCF-Crime-Frames-112', '/content/detections.csv')

import pandas as pd
import numpy as np
import os
import cv2
from google.colab import drive

def generate_anomaly_labels(detections_csv_path, sequence_length=5):
    df = pd.read_csv(detections_csv_path)
    df = df.sort_values(by='frame_path').reset_index(drop=True)

    frame_to_detections = {}
    frames = sorted(df['frame_path'].unique())

    for frame in frames:
        frame_to_detections[frame] = df[df['frame_path'] == frame]

    anomaly_labels = []
    sequence_paths = []

    # Thresholds
    CROWD_THRESHOLD = 2
    MOTION_THRESHOLD = 10
    OBJECT_COUNT_THRESHOLD = 1
    COLLISION_IOU_THRESHOLD = 0.01
    UNEXPECTED_CLASSES = [2, 5, 7]  # Car, Bus, Truck

    for i in range(len(frames) - sequence_length):
        current_sequence = frames[i:i+sequence_length]
        last_frame = current_sequence[-1]
        current_detections = frame_to_detections[last_frame]

        # --- 1. Crowd Anomaly ---
        num_persons = np.sum(current_detections['class_id'] == 0)
        crowd = 1 if num_persons > CROWD_THRESHOLD else 0

        # --- 2. Motion Anomaly ---
        motion = 0
        if i > 0:
            prev_detections = frame_to_detections[frames[i+sequence_length-2]]
            for _, curr in current_detections.iterrows():
                matches = prev_detections[prev_detections['class_id'] == curr['class_id']]
                for _, prev in matches.iterrows():
                    dx = ((curr['xmin'] + curr['xmax']) / 2) - ((prev['xmin'] + prev['xmax']) / 2)
                    dy = ((curr['ymin'] + curr['ymax']) / 2) - ((prev['ymin'] + prev['ymax']) / 2)
                    if np.sqrt(dx**2 + dy**2) > MOTION_THRESHOLD:
                        motion = 1
                        break

        # --- 3. Object Count Anomaly ---
        object_count = 0
        if i > 0:
            prev_count = len(frame_to_detections[frames[i+sequence_length-2]])
            curr_count = len(current_detections)
            if abs(curr_count - prev_count) > OBJECT_COUNT_THRESHOLD:
                object_count = 1

        # --- 4. Scene Context Anomaly ---
        scene_context = int(any(current_detections['class_id'].isin(UNEXPECTED_CLASSES)))

        # --- 5. Collision Anomaly ---
        collision = 0
        boxes = current_detections[['xmin', 'ymin', 'xmax', 'ymax']].values
        for j in range(len(boxes)):
            for k in range(j+1, len(boxes)):
                xa = max(boxes[j][0], boxes[k][0])
                ya = max(boxes[j][1], boxes[k][1])
                xb = min(boxes[j][2], boxes[k][2])
                yb = min(boxes[j][3], boxes[k][3])
                inter = max(0, xb - xa + 1) * max(0, yb - ya + 1)
                area_a = (boxes[j][2] - boxes[j][0] + 1) * (boxes[j][3] - boxes[j][1] + 1)
                area_b = (boxes[k][2] - boxes[k][0] + 1) * (boxes[k][3] - boxes[k][1] + 1)
                iou = inter / float(area_a + area_b - inter)
                if iou > COLLISION_IOU_THRESHOLD:
                    collision = 1
                    break



        labels = [crowd, motion, object_count, scene_context, collision, appearance]
        anomaly_labels.append(labels)
        sequence_paths.append(current_sequence)

    print(f"✅ Generated {len(anomaly_labels)} anomaly label rows.")
    return sequence_paths, anomaly_labels

# 🔄 Save to Drive
def save_labels_to_drive(sequence_paths, anomaly_labels, save_path):
    drive.mount('/content/drive')

    records = []
    for seq, label in zip(sequence_paths, anomaly_labels):
        records.append({
            'start_frame': seq[0],
            'end_frame': seq[-1],
            'crowd': label[0],
            'motion': label[1],
            'object_count': label[2],
            'scene_context': label[3],
            'collision': label[4],
            'appearance': label[5],
        })

    df = pd.DataFrame(records)
    df.to_csv(save_path, index=False)
    print(f"✅ Saved anomaly_labels.csv to: {save_path}")

#  Run both steps
sequence_paths, anomaly_labels = generate_anomaly_labels('/content/detections_anomaly.csv', sequence_length=5)
save_labels_to_drive(sequence_paths, anomaly_labels, '/content/drive/MyDrive/detection_anomaly_labels.csv')

import os
import cv2
import torch
import numpy as np
import pandas as pd
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from sklearn.model_selection import train_test_split
from google.colab import drive
from IPython.display import display

# Constants
LABEL_CSV_PATH = '/content/detection_anomalylabels.csv'
MODEL_SAVE_PATH = '/content/drive/MyDrive/multitask__attention__model_.pth'

# Dataset Class
class AnomalyDataset(Dataset):
    def __init__(self, dataframe, sequence_length=10, img_size=(112, 112)):
        self.df = dataframe.reset_index(drop=True)
        self.sequence_length = sequence_length
        self.img_size = img_size

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        folder = os.path.dirname(row['start_frame'])
        all_frames = sorted([f for f in os.listdir(folder) if f.endswith(('.png', '.jpg'))])

        try:
            start_idx = all_frames.index(os.path.basename(row['start_frame']))
        except ValueError:
            start_idx = max(0, len(all_frames) - self.sequence_length)

        frames = []
        for i in range(start_idx, min(start_idx + self.sequence_length, len(all_frames))):
            frame_path = os.path.join(folder, all_frames[i])
            img = cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                raise ValueError(f"Could not read image: {frame_path}")
            img = cv2.resize(img, self.img_size)
            frames.append(img / 255.0)

        if len(frames) < self.sequence_length:
            frames += [frames[-1]] * (self.sequence_length - len(frames))

        x = np.mean(np.stack(frames), axis=0)[np.newaxis, :, :]  # (1, H, W)
        y = row[['crowd', 'motion', 'object_count', 'scene_context', 'collision', 'appearance']].values.astype(np.float32)
        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)

# Model Architecture
class MultitaskAttentionCNN(nn.Module):
    def __init__(self, num_tasks=6):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.flatten = nn.Flatten()
        self.attn = nn.Sequential(
            nn.Linear(64 * 28 * 28, 512),
            nn.ReLU(),
            nn.Linear(512, 64 * 28 * 28),
            nn.Sigmoid()
        )
        self.shared = nn.Linear(64 * 28 * 28, 128)
        self.heads = nn.ModuleList([nn.Sequential(nn.Linear(128, 1), nn.Sigmoid()) for _ in range(num_tasks)])

    def forward(self, x):
        f = self.features(x)
        flat = self.flatten(f)
        attn = self.attn(flat)
        shared = self.shared(flat * attn)
        return torch.cat([head(shared) for head in self.heads], dim=1), attn

# Training Function
def train_model(model, loader, device, epochs=10):
    model.to(device)
    opt = torch.optim.Adam(model.parameters(), lr=1e-3)
    loss_fn = nn.BCELoss()

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for batch_idx, (x, y) in enumerate(loader):
            x, y = x.to(device), y.to(device)
            out, _ = model(x)
            loss = loss_fn(out, y)

            opt.zero_grad()
            loss.backward()
            opt.step()

            total_loss += loss.item()
            if (batch_idx + 1) % 10 == 0:
                print(f"  Batch {batch_idx+1}/{len(loader)} | Loss: {loss.item():.4f}")

        print(f"Epoch {epoch+1}/{epochs} - Avg Loss: {total_loss/len(loader):.4f}")

    torch.save(model.state_dict(), MODEL_SAVE_PATH)
    print(f"Model saved to {MODEL_SAVE_PATH}")

# Evaluation Function
def evaluate_model(model, loader, device):
    model.eval()
    y_true, y_pred = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            preds, _ = model(x)
            # Ensure tensors are on CPU before converting to numpy
            y_true.append(y.detach().cpu().tolist())
            y_pred.append((preds.detach().cpu() > 0.5).int().tolist())


    y_true = np.vstack(y_true)
    y_pred = np.vstack(y_pred)
    labels = ['Crowd', 'Motion', 'Object Count', 'Scene Context', 'Collision']

    results = []
    for i, name in enumerate(labels):
        acc = accuracy_score(y_true[:, i], y_pred[:, i])
        prec = precision_score(y_true[:, i], y_pred[:, i], zero_division=0)
        rec = recall_score(y_true[:, i], y_pred[:, i], zero_division=0)
        f1 = f1_score(y_true[:, i], y_pred[:, i], zero_division=0)

        results.append({
            'Task': name,
            'Accuracy': f"{acc:.4f}",
            'Precision': f"{prec:.4f}",
            'Recall': f"{rec:.4f}",
            'F1 Score': f"{f1:.4f}"
        })

    df_results = pd.DataFrame(results)
    print("\nEvaluation Results:")
    display(df_results)
    return df_results

# Main Execution
def main():
    # Mount Google Drive
    drive.mount('/content/drive', force_remount=True)

    # Initialize device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nUsing device: {device}")

    # Load and prepare data
    print("\nLoading dataset...")
    try:
        full_df = pd.read_csv(LABEL_CSV_PATH)
    except FileNotFoundError:
        raise FileNotFoundError(f"Could not find label CSV at {LABEL_CSV_PATH}")

    train_df, test_df = train_test_split(full_df, test_size=0.2, random_state=42)

    # Create datasets and loaders
    train_dataset = AnomalyDataset(train_df)
    test_dataset = AnomalyDataset(test_df)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32)

    # Initialize model
    model = MultitaskAttentionCNN().to(device)

    # Check for existing model
    if os.path.exists(MODEL_SAVE_PATH):
        print(f"\nFound saved model at {MODEL_SAVE_PATH}")
        try:
            model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))
            model.eval()
            print("✅ Model loaded successfully")

            # Evaluate existing model
            print("\nEvaluating loaded model...")
            evaluate_model(model, test_loader, device)
        except Exception as e:
            print(f"❌ Error loading model: {e}")
            print("Training new model instead...")
            train_model(model, train_loader, device, epochs=10)
            evaluate_model(model, test_loader, device)
    else:
        print("\nNo saved model found")
        print("🚀 Starting training...")
        train_model(model, train_loader, device, epochs=10)
        print("\nEvaluating trained model...")
        evaluate_model(model, test_loader, device)

if __name__ == "__main__":
    main()

import pandas as pd
import cv2
import os
from google.colab.patches import cv2_imshow

# ✅ Load CSV with 6 anomaly types
csv_path = '/content/detection_anomalylabels.csv'  # Update if needed
df = pd.read_csv(csv_path)

# ✅ Define anomaly type labels
anomaly_types = ['crowd', 'motion', 'object_count', 'scene_context', 'collision']

for idx, row in df.iterrows():
    frame_path = row['start_frame']
    if not os.path.exists(frame_path):
        print(f"⚠️ Missing frame: {frame_path}")
        continue

    frame = cv2.imread(frame_path)
    if frame is None:
        print(f"⚠️ Unable to read: {frame_path}")
        continue

    # ✅ Detect anomaly type(s)
    detected_anomalies = [atype for atype in anomaly_types if row[atype] == 1]
    is_anomaly = len(detected_anomalies) > 0

    # ✅ Color: Red = anomaly, Green = normal
    color = (0, 0, 255) if is_anomaly else (0, 255, 0)  # BGR

    # ✅ Draw only a rectangle (no label inside)
    height, width = frame.shape[:2]
    cv2.rectangle(frame, (10, 10), (width - 10, height - 10), color, 2)

    # ✅ Show the frame
    cv2_imshow(frame)
    cv2.waitKey(1)

    # ✅ Print the anomalies outside the image
    print(f" Frame: {frame_path}")
    if is_anomaly:
        print(f"Detected Anomalies: {', '.join(detected_anomalies)}")
    else:
        print(" Normal Behavior")

print("✅ All frames processed.")